{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1989ea6e",
   "metadata": {},
   "source": [
    "# Mask Classification using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ccf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb660bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "#data = pd.read_csv('G:/AI Project/mask-classification-pytorch/dataset.csv')\n",
    "#data.head()\n",
    "\n",
    "data_path = \"G:/AI Project/mask-classification-pytorch/dataset.csv\"\n",
    "img_path = \"G:\\\\AI Project\\\\mask-classification-pytorch\\\\dataset\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cd7d9b",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbec07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class MaskImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 1])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.img_labels.iloc[idx, 2]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa96879",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                ])\n",
    "\n",
    "full_dataset = MaskImageDataset(data_path, img_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64027854",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_data = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34535c25",
   "metadata": {},
   "source": [
    "# Creating Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287b5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, Linear, MaxPool2d, Module, BatchNorm2d\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class MaskNetV2(Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        ''' Initializing the model'''\n",
    "        super(MaskNetV2, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn_1 = BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2_1 = Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn_2 = BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3_1 = Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn_3 = BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4_1 = Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn_4 = BatchNorm2d(256)\n",
    "        \n",
    "        self.maxpool = MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        self.fc1 = Linear(36864, 1024)\n",
    "        self.fc2 = Linear(1024, 512)\n",
    "        self.fc3 = Linear(512, 5)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.bn_1(self.conv1_1(x)), inplace=True)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.bn_2(self.conv2_1(x)), inplace=True)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.bn_3(self.conv3_1(x)), inplace=True)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = F.relu(self.bn_4(self.conv4_1(x)), inplace=True)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x), inplace=True)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        \n",
    "        x = F.relu(self.fc2(x), inplace=True)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d079fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskNetV2()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9dd84",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21daa660",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, train_loader, device):\n",
    "    learning_rate = 0.001\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
    "    \n",
    "    train_losses = []\n",
    "    acc_list = []\n",
    "    epochs = 45\n",
    "    \n",
    "    for i in range(1, epochs+1):\n",
    "        start = time.time()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for j, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "            correct += (predicted == labels).sum().item() \n",
    "        \n",
    "            \n",
    "        \n",
    "        train_loss = running_loss/len(train_loader.sampler)\n",
    "        train_losses.append(train_loss)\n",
    "        accuracy = (correct / total) * 100\n",
    "        acc_list.append(accuracy)\n",
    "        \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tAccuracy: {:.6f}'.format(\n",
    "        i, train_loss, accuracy))\n",
    "        elapsed = time.time() - start\n",
    "        print(\"Elapsed time: \" + time.strftime(\"%H:%M:%S.{}\".format(str(elapsed % 1)[2:])[:11], time.gmtime(elapsed)))\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    torch.save(model.state_dict(), \"G:/AI Project/mask-classification-pytorch/saved_models/masknetv2_4.pt\")\n",
    "    torch.save(model, \"G:/AI Project/mask-classification-pytorch/saved_models/masknetv2_4_full.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e48716",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainModel(model, train_data, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a10783",
   "metadata": {},
   "source": [
    "# Model Evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import  DataLoader,random_split\n",
    "from torchvision import datasets,transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data_path = \"G:/AI Project/mask-classification-pytorch/dataset.csv\"\n",
    "img_path = \"G:\\\\AI Project\\\\mask-classification-pytorch\\\\dataset\\\\\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") \n",
    "#device = torch.device('cpu')\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                ])\n",
    "\n",
    "full_dataset = MaskImageDataset(data_path, img_path, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "#train_data = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_data = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "the_model = MaskNetV2()\n",
    "the_model = the_model.to(device)\n",
    "path = \"G:/AI Project/mask-classification-pytorch/saved_models/masknetv2_3_full.pt\"\n",
    "the_model=torch.load(path)\n",
    "#the_model=torch.load(\"G:/AI Project/mask-classification-pytorch/saved_models/masknetv2_3_full.pt\",torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea70ee",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbd1326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "def test_model(model,testing_data,DEVICE):\n",
    "      \n",
    "    testing_loss = 0\n",
    "    correct_prediction = 0 \n",
    "    data_size = 0\n",
    "    prediction1=[]\n",
    "    for images, labels in testing_data:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)          \n",
    "            data_size += len(images)\n",
    "            prediction = model(images)\n",
    "            \n",
    "            prediction1.append(prediction)\n",
    "            \n",
    "            testing_loss += cross_entropy(prediction, labels).item()\n",
    "            correct_prediction += (prediction.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "\n",
    "    accuracy = correct_prediction/data_size\n",
    "    testing_loss = testing_loss/data_size\n",
    "\n",
    "    print('\\nTesting:')\n",
    "    print(f\"Correct prediction: {correct_prediction}/{data_size} and accuracy: {accuracy} and loss: {testing_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601de92c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "test_model(the_model,test_data,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f46fde",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "def get_labels_N_prediction(model,loader,DEVICE):\n",
    "    all_labels = []\n",
    "    all_prediction = []\n",
    "\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        images = images.to(DEVICE)\n",
    "\n",
    "        prediction = model(images).to(torch.device(\"cpu\")).argmax(dim=1).detach().numpy()\n",
    "        labels = labels.to(torch.device(\"cpu\")).detach().numpy()\n",
    "\n",
    "        all_prediction = np.append(all_prediction,prediction)\n",
    "        all_labels = np.append(all_labels,labels)\n",
    "\n",
    "    return [all_labels,all_prediction]\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    labels_N_prediction = get_labels_N_prediction(the_model, test_data, device)\n",
    "\n",
    "    \n",
    "print(classification_report(labels_N_prediction[0], labels_N_prediction[1]))\n",
    "conf_matrix = confusion_matrix(labels_N_prediction[0], labels_N_prediction[1])\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2e687",
   "metadata": {},
   "source": [
    "## Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "#ACCURACY SCORE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib\n",
    "#y_pred = the_model.predict(test_dataset)\n",
    "y_pred =labels_N_prediction[1]\n",
    "y_test =labels_N_prediction[0]\n",
    "print(\"Accuracy : \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727270b",
   "metadata": {},
   "source": [
    "## Precision, Recal, FScore, Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRECISION , RECALL,FSCORE,SUPPORT\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "d=()\n",
    "d=precision_recall_fscore_support(labels_N_prediction[0], y_pred)\n",
    "prec = d[0].tolist()\n",
    "recall = d[1].tolist()\n",
    "fscore = d[2].tolist()\n",
    "support = d[3].tolist()\n",
    "#precision_recall_fscore_support(y_test, y_pred,average=\"macro\")\n",
    "print(\"prec --\",prec)\n",
    "print(\"recall --\",recall)\n",
    "print(\"fscore --\",fscore)\n",
    "print(\"support --\",support)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5b00f",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFICATION REPORT - PRECISION , RECALL,FSCORE,SUPPORT\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#PLOTTING CLASSIFICATION REPORT\n",
    "import seaborn as sns\n",
    "from pylab import savefig\n",
    "h= classification_report(y_test, y_pred , output_dict=True)\n",
    "svm =sns.heatmap(pd.DataFrame(h).iloc[:-1, :].T, annot=True)\n",
    "figure = svm.get_figure()\n",
    "\n",
    "figure.savefig('Classification report.png')\n",
    "\n",
    "#CONFUSION MATRIX & PLOTTING IT\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred).tolist()\n",
    "cm = sns.heatmap(confusion_matrix, annot=True, fmt='d')\n",
    "\n",
    "\n",
    "cm.plot()\n",
    "matplotlib.pyplot.show()\n",
    "matplotlib.pyplot.savefig('confusion metrics.png')\n",
    "\n",
    "#PLOTTING PRECISION AND RECALL GRAPH\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "disp = PrecisionRecallDisplay(precision=precision_recall_fscore_support(y_test, y_pred)[0],recall=precision_recall_fscore_support(y_test, y_pred)[1])\n",
    "disp.plot()\n",
    "matplotlib.pyplot.show()\n",
    "matplotlib.pyplot.savefig('Precision vs Recall.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43dc017",
   "metadata": {},
   "source": [
    "# Testing trained model on new Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550f4ca",
   "metadata": {},
   "source": [
    "## Loading saved trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71debf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"G:/AI Project/mask-classification-pytorch/saved_models/masknetv2_3_full.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def predictImage(model, imagePath, device, labels={0:'cloth', 1:'N95', 2:'N95 with valve', 3:'No Mask', 4:'Surgical'}):\n",
    "    \n",
    "    \n",
    "    transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                ])\n",
    "    image = Image.open(imagePath).convert('RGB')\n",
    "    imageD = Image.open(imagePath).convert('RGB')\n",
    "    \n",
    "    image = transform(image)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device)\n",
    "        output = model(image.unsqueeze(0))\n",
    "    pred = list(output.argmax(dim=1).cpu().numpy())\n",
    "    #print(pred)\n",
    "    \n",
    "    plt.imshow(imageD)    \n",
    "    print(\"Prediction : \" + labels[pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb59569",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictImage(model, \"G:/AI Project/mask-classification-pytorch/try1.jpg\", \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934a4d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
